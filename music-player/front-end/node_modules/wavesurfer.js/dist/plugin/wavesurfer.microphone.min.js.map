{"version":3,"sources":["webpack:///webpack/universalModuleDefinition?5ca6***","webpack:///wavesurfer.microphone.min.js","webpack:///webpack/bootstrap 2e5ff4b2126b5af12ddc?6e16***","webpack:///./src/plugin/microphone.js"],"names":["root","factory","exports","module","define","amd","this","modules","__webpack_require__","moduleId","installedModules","i","l","call","m","c","value","d","name","getter","o","Object","defineProperty","configurable","enumerable","get","n","__esModule","object","property","prototype","hasOwnProperty","p","s","2","_classCallCheck","instance","Constructor","TypeError","_createClass","defineProperties","target","props","length","descriptor","writable","key","protoProps","staticProps","MicrophonePlugin","params","ws","_this","wavesurfer","active","paused","reloadBufferFunction","e","reloadBuffer","promisifiedOldGUM","constraints","successCallback","errorCallback","getUserMedia","navigator","webkitGetUserMedia","mozGetUserMedia","msGetUserMedia","Promise","reject","Error","undefined","mediaDevices","video","audio","bufferSize","numberOfInputChannels","numberOfOutputChannels","_onBackendCreated","micContext","backend","getAudioContext","deferInit","on","un","stop","_this2","then","data","gotStream","catch","deviceError","pause","play","start","connect","disconnect","stopDevice","empty","stream","result","detectBrowser","browser","version","getTracks","forEach","mediaStreamSource","createMediaStreamSource","levelChecker","createScriptProcessor","destination","onaudioprocess","event","loadDecodedBuffer","inputBuffer","fireEvent","code","uastring","expr","pos","match","parseInt","minVersion","window","extractVersion","userAgent","webkitRTCPeerConnection","default"],"mappings":";;;;;CAAA,SAAAA,EAAAC,GACA,gBAAAC,UAAA,gBAAAC,QACAA,OAAAD,QAAAD,IACA,kBAAAG,gBAAAC,IACAD,OAAA,gBAAAH,GACA,gBAAAC,SACAA,QAAA,WAAAD,KAEAD,EAAA,WAAAA,EAAA,eAA+CA,EAAA,sBAAAC,MAC9CK,KAAA,WACD,MCAgB,UAAUC,GCN1B,QAAAC,GAAAC,GAGA,GAAAC,EAAAD,GACA,MAAAC,GAAAD,GAAAP,OAGA,IAAAC,GAAAO,EAAAD,IACAE,EAAAF,EACAG,GAAA,EACAV,WAUA,OANAK,GAAAE,GAAAI,KAAAV,EAAAD,QAAAC,IAAAD,QAAAM,GAGAL,EAAAS,GAAA,EAGAT,EAAAD,QAvBA,GAAAQ,KA+DA,OAnCAF,GAAAM,EAAAP,EAGAC,EAAAO,EAAAL,EAGAF,EAAAG,EAAA,SAAAK,GAA2C,MAAAA,IAG3CR,EAAAS,EAAA,SAAAf,EAAAgB,EAAAC,GACAX,EAAAY,EAAAlB,EAAAgB,IACAG,OAAAC,eAAApB,EAAAgB,GACAK,cAAA,EACAC,YAAA,EACAC,IAAAN,KAMAX,EAAAkB,EAAA,SAAAvB,GACA,GAAAgB,GAAAhB,KAAAwB,WACA,WAA2B,MAAAxB,GAAA,SAC3B,WAAiC,MAAAA,GAEjC,OADAK,GAAAS,EAAAE,EAAA,IAAAA,GACAA,GAIAX,EAAAY,EAAA,SAAAQ,EAAAC,GAAsD,MAAAR,QAAAS,UAAAC,eAAAlB,KAAAe,EAAAC,IAGtDrB,EAAAwB,EAAA,8BAGAxB,IAAAyB,EAAA,KDgBMC,EACA,SAAU/B,EAAQD,EAASM,GAEjC,YASA,SAAS2B,GAAgBC,EAAUC,GAAe,KAAMD,YAAoBC,IAAgB,KAAM,IAAIC,WAAU,qCANhHjB,OAAOC,eAAepB,EAAS,cAC3Bc,OAAO,GAGX,IAAIuB,GAAe,WAAc,QAASC,GAAiBC,EAAQC,GAAS,IAAK,GAAI/B,GAAI,EAAGA,EAAI+B,EAAMC,OAAQhC,IAAK,CAAE,GAAIiC,GAAaF,EAAM/B,EAAIiC,GAAWpB,WAAaoB,EAAWpB,aAAc,EAAOoB,EAAWrB,cAAe,EAAU,SAAWqB,KAAYA,EAAWC,UAAW,GAAMxB,OAAOC,eAAemB,EAAQG,EAAWE,IAAKF,IAAiB,MAAO,UAAUP,EAAaU,EAAYC,GAAiJ,MAA9HD,IAAYP,EAAiBH,EAAYP,UAAWiB,GAAiBC,GAAaR,EAAiBH,EAAaW,GAAqBX,MEnD3gBY,EF8FE,WE3EnB,QAAAA,GAAYC,EAAQC,GAAI,GAAAC,GAAA9C,IAAA6B,GAAA7B,KAAA2C,GACpB3C,KAAK4C,OAASA,EACd5C,KAAK+C,WAAaF,EAElB7C,KAAKgD,QAAS,EACdhD,KAAKiD,QAAS,EACdjD,KAAKkD,qBAAuB,SAAAC,GAAA,MAAKL,GAAKM,aAAaD,GAGnD,IAAME,GAAoB,SAACC,EAAaC,EAAiBC,GAErD,GAAMC,GAAgBC,UAAUD,cAC5BC,UAAUC,oBACVD,UAAUE,iBACVF,UAAUG,cAId,OAAKJ,GAOE,GAAIK,SAAQ,SAACP,EAAiBC,GACjCC,EAAalD,KAAKmD,UAAWJ,EAAaC,EAAiBC,KAPpDM,QAAQC,OACX,GAAIC,OAAM,yDAWSC,KAA3BP,UAAUQ,eACVR,UAAUQ,qBAM8BD,KAAxCP,UAAUQ,aAAaT,eACvBC,UAAUQ,aAAaT,aAAeJ,GAE1CrD,KAAKsD,YAActD,KAAK4C,OAAOU,cAC3Ba,OAAO,EACPC,OAAO,GAEXpE,KAAKqE,WAAarE,KAAK4C,OAAOyB,YAAc,KAC5CrE,KAAKsE,sBAAwBtE,KAAK4C,OAAO0B,uBAAyB,EAClEtE,KAAKuE,uBAAyBvE,KAAK4C,OAAO2B,wBAA0B,EAEpEvE,KAAKwE,kBAAoB,WAErB1B,EAAK2B,WAAa3B,EAAKC,WAAW2B,QAAQC,mBFiYlD,MAxWA1C,GAAaU,EAAkB,OAC3BH,IAAK,SAWL9B,MAAO,SEjGGkC,GACV,OACIhC,KAAM,aACNgE,aAAWhC,IAAUA,EAAOgC,YAAYhC,EAAOgC,UAC/ChC,OAAQA,EACRd,SAAUa,OF6JlBV,EAAaU,IACTH,IAAK,OACL9B,MAAO,WEnGPV,KAAK+C,WAAW8B,GAAG,kBAAmB7E,KAAKwE,mBACvCxE,KAAK+C,WAAW2B,SAChB1E,KAAKwE,uBF6GThC,IAAK,UACL9B,MAAO,WEpGPV,KAAKiD,QAAS,EAEdjD,KAAK+C,WAAW+B,GAAG,kBAAmB9E,KAAKwE,mBAC3CxE,KAAK+E,UFgHLvC,IAAK,QACL9B,MAAO,WE1GH,GAAAsE,GAAAhF,IACJ0D,WAAUQ,aAAaT,aAAazD,KAAKsD,aACpC2B,KAAK,SAACC,GAAD,MAAUF,GAAKG,UAAUD,KAC9BE,MAAM,SAACF,GAAD,MAAUF,GAAKK,YAAYH,QFsHtC1C,IAAK,aACL9B,MAAO,WEhHFV,KAAKgD,QAKNhD,KAAKiD,QAAUjD,KAAKiD,OAEhBjD,KAAKiD,OACLjD,KAAKsF,QAELtF,KAAKuF,QARTvF,KAAKwF,WFmIThD,IAAK,OACL9B,MAAO,WEnHPV,KAAKiD,QAAS,EAEdjD,KAAKyF,aF4HLjD,IAAK,QACL9B,MAAO,WEtHPV,KAAKiD,QAAS,EAIdjD,KAAK0F,gBFgILlD,IAAK,OACL9B,MAAO,WEzHHV,KAAKgD,SAELhD,KAAK2F,aAGL3F,KAAK+C,WAAW6C,YFmIpBpD,IAAK,aACL9B,MAAO,WEtHP,GANAV,KAAKgD,QAAS,EAGdhD,KAAK0F,aAGD1F,KAAK6F,OAAQ,CACb,GAAMC,GAAS9F,KAAK+F,eAIpB,KAAwB,WAAnBD,EAAOE,SAAwBF,EAAOG,SAAW,IAC9B,YAAnBH,EAAOE,SAAyBF,EAAOG,SAAW,IAC/B,SAAnBH,EAAOE,UACJhG,KAAK6F,OAAOK,UAEZ,WADAlG,MAAK6F,OAAOK,YAAYC,QAAQ,SAAAN,GAAA,MAAUA,GAAOd,QAKzD/E,MAAK6F,OAAOd,WFuIhBvC,IAAK,UACL9B,MAAO,eEhIauD,KAAhBjE,KAAK6F,SAEL7F,KAAKoG,kBAAoBpG,KAAKyE,WAAW4B,wBAAwBrG,KAAK6F,QAEtE7F,KAAKsG,aAAetG,KAAKyE,WAAW8B,sBAChCvG,KAAKqE,WACLrE,KAAKsE,sBACLtE,KAAKuE,wBAETvE,KAAKoG,kBAAkBX,QAAQzF,KAAKsG,cAEpCtG,KAAKsG,aAAab,QAAQzF,KAAKyE,WAAW+B,aAC1CxG,KAAKsG,aAAaG,eAAiBzG,KAAKkD,yBFsI5CV,IAAK,aACL9B,MAAO,eE/HwBuD,KAA3BjE,KAAKoG,mBACLpG,KAAKoG,kBAAkBV,iBAGDzB,KAAtBjE,KAAKsG,eACLtG,KAAKsG,aAAaZ,aAClB1F,KAAKsG,aAAaG,mBAAiBxC,OFyIvCzB,IAAK,eACL9B,MAAO,SEnIEgG,GACJ1G,KAAKiD,SACNjD,KAAK+C,WAAW6C,QAChB5F,KAAK+C,WAAW4D,kBAAkBD,EAAME,iBF8I5CpE,IAAK,YACL9B,MAAO,SEtIDmF,GACN7F,KAAK6F,OAASA,EACd7F,KAAKgD,QAAS,EAGdhD,KAAKuF,OAGLvF,KAAK6G,UAAU,cAAehB,MF8I9BrD,IAAK,cACL9B,MAAO,SEzICoG,GAER9G,KAAK6G,UAAU,cAAeC,MFqJ9BtE,IAAK,iBACL9B,MAAO,SE5IIqG,EAAUC,EAAMC,GAC3B,GAAMC,GAAQH,EAASG,MAAMF,EAC7B,OAAOE,IAASA,EAAM7E,QAAU4E,GAAOE,SAASD,EAAMD,GAAM,OFsJ5DzE,IAAK,gBACL9B,MAAO,WE7IP,GAAMoF,KAMN,OALAA,GAAOE,QAAU,KACjBF,EAAOG,QAAU,KACjBH,EAAOsB,WAAa,KAGE,mBAAXC,SAA2BA,OAAO3D,UAMzCA,UAAUE,iBACVkC,EAAOE,QAAU,UACjBF,EAAOG,QAAUjG,KAAKsH,eAAe5D,UAAU6D,UAAW,sBAAuB,GACjFzB,EAAOsB,WAAa,GACbtB,GAIPpC,UAAUC,oBAAsB0D,OAAOG,yBACvC1B,EAAOE,QAAU,SACjBF,EAAOG,QAAUjG,KAAKsH,eAAe5D,UAAU6D,UAAW,2BAA4B,GACtFzB,EAAOsB,WAAa,GACbtB,GAIPpC,UAAUQ,cAAgBR,UAAU6D,UAAUL,MAAM,uBACpDpB,EAAOE,QAAU,OACjBF,EAAOG,QAAUjG,KAAKsH,eAAe5D,UAAU6D,UAAW,qBAAsB,GAChFzB,EAAOsB,WAAa,MACbtB,IAIXA,EAAOE,QAAU,2BACVF,IA9BHA,EAAOE,QAAU,2BACVF,OFgLRnD,IAGX/C,GAAQ6H,QE1ca9E,EF2crB9C,EAAOD,QAAUA,EAAiB","file":"wavesurfer.microphone.min.js","sourcesContent":["(function webpackUniversalModuleDefinition(root, factory) {\n\tif(typeof exports === 'object' && typeof module === 'object')\n\t\tmodule.exports = factory();\n\telse if(typeof define === 'function' && define.amd)\n\t\tdefine(\"microphone\", [], factory);\n\telse if(typeof exports === 'object')\n\t\texports[\"microphone\"] = factory();\n\telse\n\t\troot[\"WaveSurfer\"] = root[\"WaveSurfer\"] || {}, root[\"WaveSurfer\"][\"microphone\"] = factory();\n})(this, function() {\nreturn \n\n\n// WEBPACK FOOTER //\n// webpack/universalModuleDefinition","(function webpackUniversalModuleDefinition(root, factory) {\n\tif(typeof exports === 'object' && typeof module === 'object')\n\t\tmodule.exports = factory();\n\telse if(typeof define === 'function' && define.amd)\n\t\tdefine(\"microphone\", [], factory);\n\telse if(typeof exports === 'object')\n\t\texports[\"microphone\"] = factory();\n\telse\n\t\troot[\"WaveSurfer\"] = root[\"WaveSurfer\"] || {}, root[\"WaveSurfer\"][\"microphone\"] = factory();\n})(this, function() {\nreturn /******/ (function(modules) { // webpackBootstrap\n/******/ \t// The module cache\n/******/ \tvar installedModules = {};\n/******/\n/******/ \t// The require function\n/******/ \tfunction __webpack_require__(moduleId) {\n/******/\n/******/ \t\t// Check if module is in cache\n/******/ \t\tif(installedModules[moduleId]) {\n/******/ \t\t\treturn installedModules[moduleId].exports;\n/******/ \t\t}\n/******/ \t\t// Create a new module (and put it into the cache)\n/******/ \t\tvar module = installedModules[moduleId] = {\n/******/ \t\t\ti: moduleId,\n/******/ \t\t\tl: false,\n/******/ \t\t\texports: {}\n/******/ \t\t};\n/******/\n/******/ \t\t// Execute the module function\n/******/ \t\tmodules[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n/******/\n/******/ \t\t// Flag the module as loaded\n/******/ \t\tmodule.l = true;\n/******/\n/******/ \t\t// Return the exports of the module\n/******/ \t\treturn module.exports;\n/******/ \t}\n/******/\n/******/\n/******/ \t// expose the modules object (__webpack_modules__)\n/******/ \t__webpack_require__.m = modules;\n/******/\n/******/ \t// expose the module cache\n/******/ \t__webpack_require__.c = installedModules;\n/******/\n/******/ \t// identity function for calling harmony imports with the correct context\n/******/ \t__webpack_require__.i = function(value) { return value; };\n/******/\n/******/ \t// define getter function for harmony exports\n/******/ \t__webpack_require__.d = function(exports, name, getter) {\n/******/ \t\tif(!__webpack_require__.o(exports, name)) {\n/******/ \t\t\tObject.defineProperty(exports, name, {\n/******/ \t\t\t\tconfigurable: false,\n/******/ \t\t\t\tenumerable: true,\n/******/ \t\t\t\tget: getter\n/******/ \t\t\t});\n/******/ \t\t}\n/******/ \t};\n/******/\n/******/ \t// getDefaultExport function for compatibility with non-harmony modules\n/******/ \t__webpack_require__.n = function(module) {\n/******/ \t\tvar getter = module && module.__esModule ?\n/******/ \t\t\tfunction getDefault() { return module['default']; } :\n/******/ \t\t\tfunction getModuleExports() { return module; };\n/******/ \t\t__webpack_require__.d(getter, 'a', getter);\n/******/ \t\treturn getter;\n/******/ \t};\n/******/\n/******/ \t// Object.prototype.hasOwnProperty.call\n/******/ \t__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };\n/******/\n/******/ \t// __webpack_public_path__\n/******/ \t__webpack_require__.p = \"localhost:8080/dist/plugin/\";\n/******/\n/******/ \t// Load entry module and return exports\n/******/ \treturn __webpack_require__(__webpack_require__.s = 2);\n/******/ })\n/************************************************************************/\n/******/ ({\n\n/***/ 2:\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n\nObject.defineProperty(exports, \"__esModule\", {\n    value: true\n});\n\nvar _createClass = function () { function defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } } return function (Constructor, protoProps, staticProps) { if (protoProps) defineProperties(Constructor.prototype, protoProps); if (staticProps) defineProperties(Constructor, staticProps); return Constructor; }; }();\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\n/**\n * @typedef {Object} MicrophonePluginParams\n * @property {MediaStreamConstraints} constraints The constraints parameter is a\n * MediaStreamConstaints object with two members: video and audio, describing\n * the media types requested. Either or both must be specified.\n * @property {number} bufferSize=4096 The buffer size in units of sample-frames.\n * If specified, the bufferSize must be one of the following values: `256`,\n * `512`, `1024`, `2048`, `4096`, `8192`, `16384`\n * @property {number} numberOfInputChannels=1 Integer specifying the number of\n * channels for this node's input. Values of up to 32 are supported.\n * @property {?boolean} deferInit Set to true to manually call\n * `initPlugin('microphone')`\n */\n\n/**\n * Visualise microphone input in a wavesurfer instance.\n *\n * @implements {PluginClass}\n * @extends {Observer}\n * @example\n * // es6\n * import MicrophonePlugin from 'wavesurfer.microphone.js';\n *\n * // commonjs\n * var MicrophonePlugin = require('wavesurfer.microphone.js');\n *\n * // if you are using <script> tags\n * var MicrophonePlugin = window.WaveSurfer.microphone;\n *\n * // ... initialising wavesurfer with the plugin\n * var wavesurfer = WaveSurfer.create({\n *   // wavesurfer options ...\n *   plugins: [\n *     MicrophonePlugin.create({\n *       // plugin options ...\n *     })\n *   ]\n * });\n */\nvar MicrophonePlugin = function () {\n    _createClass(MicrophonePlugin, null, [{\n        key: 'create',\n\n        /**\n         * Microphone plugin definition factory\n         *\n         * This function must be used to create a plugin definition which can be\n         * used by wavesurfer to correctly instantiate the plugin.\n         *\n         * @param  {MicrophonePluginParams} params parameters use to initialise the plugin\n         * @return {PluginDefinition} an object representing the plugin\n         */\n        value: function create(params) {\n            return {\n                name: 'microphone',\n                deferInit: params && params.deferInit ? params.deferInit : false,\n                params: params,\n                instance: MicrophonePlugin\n            };\n        }\n    }]);\n\n    function MicrophonePlugin(params, ws) {\n        var _this = this;\n\n        _classCallCheck(this, MicrophonePlugin);\n\n        this.params = params;\n        this.wavesurfer = ws;\n\n        this.active = false;\n        this.paused = false;\n        this.reloadBufferFunction = function (e) {\n            return _this.reloadBuffer(e);\n        };\n\n        // cross-browser getUserMedia\n        var promisifiedOldGUM = function promisifiedOldGUM(constraints, successCallback, errorCallback) {\n            // get ahold of getUserMedia, if present\n            var getUserMedia = navigator.getUserMedia || navigator.webkitGetUserMedia || navigator.mozGetUserMedia || navigator.msGetUserMedia;\n            // Some browsers just don't implement it - return a rejected\n            // promise with an error to keep a consistent interface\n            if (!getUserMedia) {\n                return Promise.reject(new Error('getUserMedia is not implemented in this browser'));\n            }\n            // otherwise, wrap the call to the old navigator.getUserMedia with\n            // a Promise\n            return new Promise(function (successCallback, errorCallback) {\n                getUserMedia.call(navigator, constraints, successCallback, errorCallback);\n            });\n        };\n        // Older browsers might not implement mediaDevices at all, so we set an\n        // empty object first\n        if (navigator.mediaDevices === undefined) {\n            navigator.mediaDevices = {};\n        }\n        // Some browsers partially implement mediaDevices. We can't just assign\n        // an object with getUserMedia as it would overwrite existing\n        // properties. Here, we will just add the getUserMedia property if it's\n        // missing.\n        if (navigator.mediaDevices.getUserMedia === undefined) {\n            navigator.mediaDevices.getUserMedia = promisifiedOldGUM;\n        }\n        this.constraints = this.params.constraints || {\n            video: false,\n            audio: true\n        };\n        this.bufferSize = this.params.bufferSize || 4096;\n        this.numberOfInputChannels = this.params.numberOfInputChannels || 1;\n        this.numberOfOutputChannels = this.params.numberOfOutputChannels || 1;\n\n        this._onBackendCreated = function () {\n            // wavesurfer's AudioContext where we'll route the mic signal to\n            _this.micContext = _this.wavesurfer.backend.getAudioContext();\n        };\n    }\n\n    _createClass(MicrophonePlugin, [{\n        key: 'init',\n        value: function init() {\n            this.wavesurfer.on('backend-created', this._onBackendCreated);\n            if (this.wavesurfer.backend) {\n                this._onBackendCreated();\n            }\n        }\n\n        /**\n         * Destroy the microphone plugin.\n         */\n\n    }, {\n        key: 'destroy',\n        value: function destroy() {\n            // make sure the buffer is not redrawn during\n            // cleanup and demolition of this plugin.\n            this.paused = true;\n\n            this.wavesurfer.un('backend-created', this._onBackendCreated);\n            this.stop();\n        }\n\n        /**\n        * Allow user to select audio input device, eg. microphone, and\n        * start the visualization.\n        */\n\n    }, {\n        key: 'start',\n        value: function start() {\n            var _this2 = this;\n\n            navigator.mediaDevices.getUserMedia(this.constraints).then(function (data) {\n                return _this2.gotStream(data);\n            }).catch(function (data) {\n                return _this2.deviceError(data);\n            });\n        }\n\n        /**\n        * Pause/resume visualization.\n        */\n\n    }, {\n        key: 'togglePlay',\n        value: function togglePlay() {\n            if (!this.active) {\n                // start it first\n                this.start();\n            } else {\n                // toggle paused\n                this.paused = !this.paused;\n\n                if (this.paused) {\n                    this.pause();\n                } else {\n                    this.play();\n                }\n            }\n        }\n\n        /**\n        * Play visualization.\n        */\n\n    }, {\n        key: 'play',\n        value: function play() {\n            this.paused = false;\n\n            this.connect();\n        }\n\n        /**\n        * Pause visualization.\n        */\n\n    }, {\n        key: 'pause',\n        value: function pause() {\n            this.paused = true;\n\n            // disconnect sources so they can be used elsewhere\n            // (eg. during audio playback)\n            this.disconnect();\n        }\n\n        /**\n        * Stop the device stream and remove any remaining waveform drawing from\n        * the wavesurfer canvas.\n        */\n\n    }, {\n        key: 'stop',\n        value: function stop() {\n            if (this.active) {\n                // stop visualization and device\n                this.stopDevice();\n\n                // empty last frame\n                this.wavesurfer.empty();\n            }\n        }\n\n        /**\n        * Stop the device and the visualization.\n        */\n\n    }, {\n        key: 'stopDevice',\n        value: function stopDevice() {\n            this.active = false;\n\n            // stop visualization\n            this.disconnect();\n\n            // stop stream from device\n            if (this.stream) {\n                var result = this.detectBrowser();\n                // MediaStream.stop is deprecated since:\n                // - Firefox 44 (https://www.fxsitecompat.com/en-US/docs/2015/mediastream-stop-has-been-deprecated/)\n                // - Chrome 45 (https://developers.google.com/web/updates/2015/07/mediastream-deprecations)\n                if (result.browser === 'chrome' && result.version >= 45 || result.browser === 'firefox' && result.version >= 44 || result.browser === 'edge') {\n                    if (this.stream.getTracks) {\n                        // note that this should not be a call\n                        this.stream.getTracks().forEach(function (stream) {\n                            return stream.stop();\n                        });\n                        return;\n                    }\n                }\n\n                this.stream.stop();\n            }\n        }\n\n        /**\n        * Connect the media sources that feed the visualization.\n        */\n\n    }, {\n        key: 'connect',\n        value: function connect() {\n            if (this.stream !== undefined) {\n                // Create an AudioNode from the stream.\n                this.mediaStreamSource = this.micContext.createMediaStreamSource(this.stream);\n\n                this.levelChecker = this.micContext.createScriptProcessor(this.bufferSize, this.numberOfInputChannels, this.numberOfOutputChannels);\n                this.mediaStreamSource.connect(this.levelChecker);\n\n                this.levelChecker.connect(this.micContext.destination);\n                this.levelChecker.onaudioprocess = this.reloadBufferFunction;\n            }\n        }\n\n        /**\n        * Disconnect the media sources that feed the visualization.\n        */\n\n    }, {\n        key: 'disconnect',\n        value: function disconnect() {\n            if (this.mediaStreamSource !== undefined) {\n                this.mediaStreamSource.disconnect();\n            }\n\n            if (this.levelChecker !== undefined) {\n                this.levelChecker.disconnect();\n                this.levelChecker.onaudioprocess = undefined;\n            }\n        }\n\n        /**\n        * Redraw the waveform.\n        */\n\n    }, {\n        key: 'reloadBuffer',\n        value: function reloadBuffer(event) {\n            if (!this.paused) {\n                this.wavesurfer.empty();\n                this.wavesurfer.loadDecodedBuffer(event.inputBuffer);\n            }\n        }\n\n        /**\n        * Audio input device is ready.\n        *\n        * @param {LocalMediaStream} stream The microphone's media stream.\n        */\n\n    }, {\n        key: 'gotStream',\n        value: function gotStream(stream) {\n            this.stream = stream;\n            this.active = true;\n\n            // start visualization\n            this.play();\n\n            // notify listeners\n            this.fireEvent('deviceReady', stream);\n        }\n\n        /**\n        * Device error callback.\n        */\n\n    }, {\n        key: 'deviceError',\n        value: function deviceError(code) {\n            // notify listeners\n            this.fireEvent('deviceError', code);\n        }\n\n        /**\n        * Extract browser version out of the provided user agent string.\n        * @param {!string} uastring userAgent string.\n        * @param {!string} expr Regular expression used as match criteria.\n        * @param {!number} pos position in the version string to be returned.\n        * @return {!number} browser version.\n        */\n\n    }, {\n        key: 'extractVersion',\n        value: function extractVersion(uastring, expr, pos) {\n            var match = uastring.match(expr);\n            return match && match.length >= pos && parseInt(match[pos], 10);\n        }\n\n        /**\n        * Browser detector.\n        * @return {object} result containing browser, version and minVersion\n        *     properties.\n        */\n\n    }, {\n        key: 'detectBrowser',\n        value: function detectBrowser() {\n            // Returned result object.\n            var result = {};\n            result.browser = null;\n            result.version = null;\n            result.minVersion = null;\n\n            // Non supported browser.\n            if (typeof window === 'undefined' || !window.navigator) {\n                result.browser = 'Not a supported browser.';\n                return result;\n            }\n\n            // Firefox.\n            if (navigator.mozGetUserMedia) {\n                result.browser = 'firefox';\n                result.version = this.extractVersion(navigator.userAgent, /Firefox\\/([0-9]+)\\./, 1);\n                result.minVersion = 31;\n                return result;\n            }\n\n            // Chrome/Chromium/Webview.\n            if (navigator.webkitGetUserMedia && window.webkitRTCPeerConnection) {\n                result.browser = 'chrome';\n                result.version = this.extractVersion(navigator.userAgent, /Chrom(e|ium)\\/([0-9]+)\\./, 2);\n                result.minVersion = 38;\n                return result;\n            }\n\n            // Edge.\n            if (navigator.mediaDevices && navigator.userAgent.match(/Edge\\/(\\d+).(\\d+)$/)) {\n                result.browser = 'edge';\n                result.version = this.extractVersion(navigator.userAgent, /Edge\\/(\\d+).(\\d+)$/, 2);\n                result.minVersion = 10547;\n                return result;\n            }\n\n            // Non supported browser default.\n            result.browser = 'Not a supported browser.';\n            return result;\n        }\n    }]);\n\n    return MicrophonePlugin;\n}();\n\nexports.default = MicrophonePlugin;\nmodule.exports = exports['default'];\n\n/***/ })\n\n/******/ });\n});\n\n\n// WEBPACK FOOTER //\n// wavesurfer.microphone.min.js"," \t// The module cache\n \tvar installedModules = {};\n\n \t// The require function\n \tfunction __webpack_require__(moduleId) {\n\n \t\t// Check if module is in cache\n \t\tif(installedModules[moduleId]) {\n \t\t\treturn installedModules[moduleId].exports;\n \t\t}\n \t\t// Create a new module (and put it into the cache)\n \t\tvar module = installedModules[moduleId] = {\n \t\t\ti: moduleId,\n \t\t\tl: false,\n \t\t\texports: {}\n \t\t};\n\n \t\t// Execute the module function\n \t\tmodules[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n\n \t\t// Flag the module as loaded\n \t\tmodule.l = true;\n\n \t\t// Return the exports of the module\n \t\treturn module.exports;\n \t}\n\n\n \t// expose the modules object (__webpack_modules__)\n \t__webpack_require__.m = modules;\n\n \t// expose the module cache\n \t__webpack_require__.c = installedModules;\n\n \t// identity function for calling harmony imports with the correct context\n \t__webpack_require__.i = function(value) { return value; };\n\n \t// define getter function for harmony exports\n \t__webpack_require__.d = function(exports, name, getter) {\n \t\tif(!__webpack_require__.o(exports, name)) {\n \t\t\tObject.defineProperty(exports, name, {\n \t\t\t\tconfigurable: false,\n \t\t\t\tenumerable: true,\n \t\t\t\tget: getter\n \t\t\t});\n \t\t}\n \t};\n\n \t// getDefaultExport function for compatibility with non-harmony modules\n \t__webpack_require__.n = function(module) {\n \t\tvar getter = module && module.__esModule ?\n \t\t\tfunction getDefault() { return module['default']; } :\n \t\t\tfunction getModuleExports() { return module; };\n \t\t__webpack_require__.d(getter, 'a', getter);\n \t\treturn getter;\n \t};\n\n \t// Object.prototype.hasOwnProperty.call\n \t__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };\n\n \t// __webpack_public_path__\n \t__webpack_require__.p = \"localhost:8080/dist/plugin/\";\n\n \t// Load entry module and return exports\n \treturn __webpack_require__(__webpack_require__.s = 2);\n\n\n\n// WEBPACK FOOTER //\n// webpack/bootstrap 2e5ff4b2126b5af12ddc","/**\n * @typedef {Object} MicrophonePluginParams\n * @property {MediaStreamConstraints} constraints The constraints parameter is a\n * MediaStreamConstaints object with two members: video and audio, describing\n * the media types requested. Either or both must be specified.\n * @property {number} bufferSize=4096 The buffer size in units of sample-frames.\n * If specified, the bufferSize must be one of the following values: `256`,\n * `512`, `1024`, `2048`, `4096`, `8192`, `16384`\n * @property {number} numberOfInputChannels=1 Integer specifying the number of\n * channels for this node's input. Values of up to 32 are supported.\n * @property {?boolean} deferInit Set to true to manually call\n * `initPlugin('microphone')`\n */\n\n/**\n * Visualise microphone input in a wavesurfer instance.\n *\n * @implements {PluginClass}\n * @extends {Observer}\n * @example\n * // es6\n * import MicrophonePlugin from 'wavesurfer.microphone.js';\n *\n * // commonjs\n * var MicrophonePlugin = require('wavesurfer.microphone.js');\n *\n * // if you are using <script> tags\n * var MicrophonePlugin = window.WaveSurfer.microphone;\n *\n * // ... initialising wavesurfer with the plugin\n * var wavesurfer = WaveSurfer.create({\n *   // wavesurfer options ...\n *   plugins: [\n *     MicrophonePlugin.create({\n *       // plugin options ...\n *     })\n *   ]\n * });\n */\nexport default class MicrophonePlugin {\n    /**\n     * Microphone plugin definition factory\n     *\n     * This function must be used to create a plugin definition which can be\n     * used by wavesurfer to correctly instantiate the plugin.\n     *\n     * @param  {MicrophonePluginParams} params parameters use to initialise the plugin\n     * @return {PluginDefinition} an object representing the plugin\n     */\n    static create(params) {\n        return {\n            name: 'microphone',\n            deferInit: params && params.deferInit ? params.deferInit : false,\n            params: params,\n            instance: MicrophonePlugin\n        };\n    }\n\n    constructor(params, ws) {\n        this.params = params;\n        this.wavesurfer = ws;\n\n        this.active = false;\n        this.paused = false;\n        this.reloadBufferFunction = e => this.reloadBuffer(e);\n\n        // cross-browser getUserMedia\n        const promisifiedOldGUM = (constraints, successCallback, errorCallback) => {\n            // get ahold of getUserMedia, if present\n            const getUserMedia = (navigator.getUserMedia ||\n                navigator.webkitGetUserMedia ||\n                navigator.mozGetUserMedia ||\n                navigator.msGetUserMedia\n            );\n            // Some browsers just don't implement it - return a rejected\n            // promise with an error to keep a consistent interface\n            if (!getUserMedia) {\n                return Promise.reject(\n                    new Error('getUserMedia is not implemented in this browser')\n                );\n            }\n            // otherwise, wrap the call to the old navigator.getUserMedia with\n            // a Promise\n            return new Promise((successCallback, errorCallback) => {\n                getUserMedia.call(navigator, constraints, successCallback, errorCallback);\n            });\n        };\n        // Older browsers might not implement mediaDevices at all, so we set an\n        // empty object first\n        if (navigator.mediaDevices === undefined) {\n            navigator.mediaDevices = {};\n        }\n        // Some browsers partially implement mediaDevices. We can't just assign\n        // an object with getUserMedia as it would overwrite existing\n        // properties. Here, we will just add the getUserMedia property if it's\n        // missing.\n        if (navigator.mediaDevices.getUserMedia === undefined) {\n            navigator.mediaDevices.getUserMedia = promisifiedOldGUM;\n        }\n        this.constraints = this.params.constraints || {\n            video: false,\n            audio: true\n        };\n        this.bufferSize = this.params.bufferSize || 4096;\n        this.numberOfInputChannels = this.params.numberOfInputChannels || 1;\n        this.numberOfOutputChannels = this.params.numberOfOutputChannels || 1;\n\n        this._onBackendCreated = () => {\n            // wavesurfer's AudioContext where we'll route the mic signal to\n            this.micContext = this.wavesurfer.backend.getAudioContext();\n        };\n    }\n\n    init() {\n        this.wavesurfer.on('backend-created', this._onBackendCreated);\n        if (this.wavesurfer.backend) {\n            this._onBackendCreated();\n        }\n    }\n\n    /**\n     * Destroy the microphone plugin.\n     */\n    destroy() {\n        // make sure the buffer is not redrawn during\n        // cleanup and demolition of this plugin.\n        this.paused = true;\n\n        this.wavesurfer.un('backend-created', this._onBackendCreated);\n        this.stop();\n    }\n\n    /**\n    * Allow user to select audio input device, eg. microphone, and\n    * start the visualization.\n    */\n    start() {\n        navigator.mediaDevices.getUserMedia(this.constraints)\n            .then((data) => this.gotStream(data))\n            .catch((data) => this.deviceError(data));\n    }\n\n    /**\n    * Pause/resume visualization.\n    */\n    togglePlay() {\n        if (!this.active) {\n            // start it first\n            this.start();\n        } else {\n            // toggle paused\n            this.paused = !this.paused;\n\n            if (this.paused) {\n                this.pause();\n            } else {\n                this.play();\n            }\n        }\n    }\n\n    /**\n    * Play visualization.\n    */\n    play() {\n        this.paused = false;\n\n        this.connect();\n    }\n\n    /**\n    * Pause visualization.\n    */\n    pause() {\n        this.paused = true;\n\n        // disconnect sources so they can be used elsewhere\n        // (eg. during audio playback)\n        this.disconnect();\n    }\n\n    /**\n    * Stop the device stream and remove any remaining waveform drawing from\n    * the wavesurfer canvas.\n    */\n    stop() {\n        if (this.active) {\n            // stop visualization and device\n            this.stopDevice();\n\n            // empty last frame\n            this.wavesurfer.empty();\n        }\n    }\n\n    /**\n    * Stop the device and the visualization.\n    */\n    stopDevice() {\n        this.active = false;\n\n        // stop visualization\n        this.disconnect();\n\n        // stop stream from device\n        if (this.stream) {\n            const result = this.detectBrowser();\n            // MediaStream.stop is deprecated since:\n            // - Firefox 44 (https://www.fxsitecompat.com/en-US/docs/2015/mediastream-stop-has-been-deprecated/)\n            // - Chrome 45 (https://developers.google.com/web/updates/2015/07/mediastream-deprecations)\n            if ((result.browser === 'chrome' && result.version >= 45) ||\n                (result.browser === 'firefox' && result.version >= 44) ||\n                (result.browser === 'edge')) {\n                if (this.stream.getTracks) { // note that this should not be a call\n                    this.stream.getTracks().forEach(stream => stream.stop());\n                    return;\n                }\n            }\n\n            this.stream.stop();\n        }\n    }\n\n    /**\n    * Connect the media sources that feed the visualization.\n    */\n    connect() {\n        if (this.stream !== undefined) {\n            // Create an AudioNode from the stream.\n            this.mediaStreamSource = this.micContext.createMediaStreamSource(this.stream);\n\n            this.levelChecker = this.micContext.createScriptProcessor(\n                this.bufferSize,\n                this.numberOfInputChannels,\n                this.numberOfOutputChannels\n            );\n            this.mediaStreamSource.connect(this.levelChecker);\n\n            this.levelChecker.connect(this.micContext.destination);\n            this.levelChecker.onaudioprocess = this.reloadBufferFunction;\n        }\n    }\n\n    /**\n    * Disconnect the media sources that feed the visualization.\n    */\n    disconnect() {\n        if (this.mediaStreamSource !== undefined) {\n            this.mediaStreamSource.disconnect();\n        }\n\n        if (this.levelChecker !== undefined) {\n            this.levelChecker.disconnect();\n            this.levelChecker.onaudioprocess = undefined;\n        }\n    }\n\n    /**\n    * Redraw the waveform.\n    */\n    reloadBuffer(event) {\n        if (!this.paused) {\n            this.wavesurfer.empty();\n            this.wavesurfer.loadDecodedBuffer(event.inputBuffer);\n        }\n    }\n\n    /**\n    * Audio input device is ready.\n    *\n    * @param {LocalMediaStream} stream The microphone's media stream.\n    */\n    gotStream(stream) {\n        this.stream = stream;\n        this.active = true;\n\n        // start visualization\n        this.play();\n\n        // notify listeners\n        this.fireEvent('deviceReady', stream);\n    }\n\n    /**\n    * Device error callback.\n    */\n    deviceError(code) {\n        // notify listeners\n        this.fireEvent('deviceError', code);\n    }\n\n    /**\n    * Extract browser version out of the provided user agent string.\n    * @param {!string} uastring userAgent string.\n    * @param {!string} expr Regular expression used as match criteria.\n    * @param {!number} pos position in the version string to be returned.\n    * @return {!number} browser version.\n    */\n    extractVersion(uastring, expr, pos) {\n        const match = uastring.match(expr);\n        return match && match.length >= pos && parseInt(match[pos], 10);\n    }\n\n    /**\n    * Browser detector.\n    * @return {object} result containing browser, version and minVersion\n    *     properties.\n    */\n    detectBrowser() {\n        // Returned result object.\n        const result = {};\n        result.browser = null;\n        result.version = null;\n        result.minVersion = null;\n\n        // Non supported browser.\n        if (typeof window === 'undefined' || !window.navigator) {\n            result.browser = 'Not a supported browser.';\n            return result;\n        }\n\n        // Firefox.\n        if (navigator.mozGetUserMedia) {\n            result.browser = 'firefox';\n            result.version = this.extractVersion(navigator.userAgent, /Firefox\\/([0-9]+)\\./, 1);\n            result.minVersion = 31;\n            return result;\n        }\n\n        // Chrome/Chromium/Webview.\n        if (navigator.webkitGetUserMedia && window.webkitRTCPeerConnection) {\n            result.browser = 'chrome';\n            result.version = this.extractVersion(navigator.userAgent, /Chrom(e|ium)\\/([0-9]+)\\./, 2);\n            result.minVersion = 38;\n            return result;\n        }\n\n        // Edge.\n        if (navigator.mediaDevices && navigator.userAgent.match(/Edge\\/(\\d+).(\\d+)$/)) {\n            result.browser = 'edge';\n            result.version = this.extractVersion(navigator.userAgent, /Edge\\/(\\d+).(\\d+)$/, 2);\n            result.minVersion = 10547;\n            return result;\n        }\n\n        // Non supported browser default.\n        result.browser = 'Not a supported browser.';\n        return result;\n    }\n}\n\n\n\n// WEBPACK FOOTER //\n// ./src/plugin/microphone.js"],"sourceRoot":""}